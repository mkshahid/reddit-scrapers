{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3de82e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchRedditThreads(subreddit, search_term):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    import requests, json, time, datetime\n",
    "    import praw\n",
    "    \n",
    "    # login credentials\n",
    "    r_creds = {\n",
    "        \"id\" : \"\",\n",
    "        \"secret\" : \"\",\n",
    "        \"user\" : \"Adventurous_Party788\",\n",
    "        \"pass\" : \"\"\n",
    "    }\n",
    "    \n",
    "    # read in credentials\n",
    "    creds_file = open('creds.json', \"r\")\n",
    "    r_creds = json.loads(creds_file.read())\n",
    "    \n",
    "    reddit = praw.Reddit(\n",
    "        client_id = r_creds['id'],\n",
    "        client_secret = r_creds['secret'],\n",
    "        username = r_creds['user'],\n",
    "        password = r_creds['pass'],\n",
    "        user_agent = 'michael'\n",
    "    )\n",
    "    \n",
    "    # access subreddit\n",
    "    subredditObj = reddit.subreddit(subreddit)\n",
    "    \n",
    "    categories = ['hot','new','top','rising']\n",
    "    dfs = []\n",
    "    \n",
    "    # loop through 4 categories (hot, new, top, rising)\n",
    "    for category in categories:\n",
    "        if category == 'hot':\n",
    "            threads = list(subredditObj.hot(limit=10))\n",
    "        elif category == 'new':\n",
    "            threads = list(subredditObj.new(limit=10))\n",
    "        elif category == 'top':\n",
    "            threads = list(subredditObj.top(limit=10))\n",
    "        else:\n",
    "            threads = list(subredditObj.rising(limit=10))\n",
    "        \n",
    "        title = [post.title for post in threads]\n",
    "        body_text = [post.selftext for post in threads]\n",
    "        body_word_count = [len(post.selftext.split()) for post in threads]\n",
    "        comment_bodies = []\n",
    "        \n",
    "        # get all comments for each of the threads\n",
    "        for thread in threads:\n",
    "            thread.comments.replace_more(limit=None)\n",
    "            allComments = ''\n",
    "            for comment in thread.comments.list():\n",
    "                allComments += comment.body + '\\n'\n",
    "            comment_bodies.append(allComments.strip())\n",
    "        \n",
    "        comments_word_count = [len(comment.split()) for comment in comment_bodies]\n",
    "        up_votes = [post.ups for post in threads]\n",
    "        url = [post.url for post in threads]\n",
    "        \n",
    "        thread_dict = {\n",
    "            'title': title,\n",
    "            'body_text' : body_text,\n",
    "            'body_word_count' : body_word_count,\n",
    "            'comment_bodies' : comment_bodies,\n",
    "            'comments_word_count' : comments_word_count,\n",
    "            'up_votes' : up_votes,\n",
    "            'url' : url,\n",
    "            'category' : category,\n",
    "            'subreddit' : subreddit\n",
    "        }\n",
    "        \n",
    "        # create and add dataframe to dfs list\n",
    "        dfs.append(pd.DataFrame(thread_dict))    \n",
    "    \n",
    "    # combine dfs\n",
    "    df = dfs[0].append(dfs[1:])\n",
    "\n",
    "    # add 'all_text' column w/ title, post body, comments\n",
    "    all_text = []\n",
    "    for index, row in df.iterrows():\n",
    "        all_text.append(row['title'] + '\\n' + row['body_text'] + row['comment_bodies'])\n",
    "    df['all_text'] = all_text\n",
    "    \n",
    "    # count num occurences of search term in all_text column (occurrence = found at least once in the row)\n",
    "    numOccurences = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if search_term in row['all_text'].lower():\n",
    "            numOccurences += 1\n",
    "    print(numOccurences)\n",
    "    \n",
    "    df.to_csv('./data/' + subreddit + '_thread_posts_comments.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90831dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/9lr88cgn3xb54w91878m0c1m0000gn/T/ipykernel_36390/1937240981.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = dfs[0].append(dfs[1:])\n"
     ]
    }
   ],
   "source": [
    "searchRedditThreads('remnantgame', 'dark souls')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
